{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bản sao của hocmay.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqX1Th0XNOv9"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9BNYYNy3M8m",
        "outputId": "3e6eb96a-a0a6-4104-f7c5-a8b82aeaa5bf"
      },
      "source": [
        "!git clone https://github.com/haianh23102000/hoc_may.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'hoc_may'...\n",
            "remote: Enumerating objects: 8328, done.\u001b[K\n",
            "remote: Counting objects: 100% (8328/8328), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8325/8325), done.\u001b[K\n",
            "remote: Total 8328 (delta 2), reused 8328 (delta 2), pack-reused 0\n",
            "Receiving objects: 100% (8328/8328), 488.02 MiB | 33.93 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "Checking out files: 100% (8327/8327), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsoH743mNvmu"
      },
      "source": [
        "TrainTest = namedtuple('TrainTest', ['train', 'test'])\n",
        "\n",
        "def get_classes():\n",
        "  classes = ['2C', '3C', '4C']\n",
        "  return classes\n",
        "\n",
        "def prepare_data(size):\n",
        "  transform_train = transforms.Compose([\n",
        "    transforms.Resize((size,size)),\n",
        "    transforms.ToTensor()  ])\n",
        "  transform_test = transforms.Compose([\n",
        "    transforms.Resize((size,size)), \n",
        "    transforms.ToTensor()  ])\n",
        "  trainset = torchvision.datasets.ImageFolder(root='/content/hoc_may/Data/train', transform=transform_train)\n",
        "  testset = torchvision.datasets.ImageFolder(root='/content/hoc_may/Data/test', transform=transform_test)\n",
        "  return TrainTest(train=trainset, test=testset)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjcutgePehvt"
      },
      "source": [
        "def prepare_loader(datasets):\n",
        "  trainloader = DataLoader(dataset=datasets.train, batch_size=32, shuffle=True, num_workers=4)\n",
        "  testloader = DataLoader(dataset=datasets.test, batch_size=32, shuffle=False, num_workers=4)\n",
        "  return TrainTest(train=trainloader, test=testloader)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J5FOP9A0HgK"
      },
      "source": [
        "def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n",
        "  true_result = []\n",
        "  pred_result = []\n",
        "\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  reporting_steps = 18\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    true_result += list(labels.cpu().numpy())\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    pred_result += list(predicted.cpu().numpy())\n",
        "   \n",
        "    loss = loss_func(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    if i % reporting_steps == reporting_steps-1:\n",
        "      print(f\"Epoch {epoch} step {i} ave_loss {running_loss/reporting_steps:.4f}\")\n",
        "      running_loss = 0.0\n",
        "  return pred_result, true_result"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqJdhdcVefO9"
      },
      "source": [
        "def test_epoch(epoch, model, loader, device):\n",
        "  true = []\n",
        "  pred = [] \n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for i, (images, labels) in enumerate(loader):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      true += list(labels.cpu().numpy())\n",
        "      pred += list(predicted.cpu().numpy())\n",
        "  return pred, true"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZMboC_S0K0Y"
      },
      "source": [
        "def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  reporting_steps = 32\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    loss = loss_func(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    if i % reporting_steps == reporting_steps-1:\n",
        "      print(f\"Epoch {epoch} step {i} ave_loss {running_loss/reporting_steps:.4f}\")\n",
        "      running_loss = 0.0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtSyVaLxeVos"
      },
      "source": [
        "def test_epoch(epoch, model, loader, device):\n",
        "  true = []\n",
        "  pred = []\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for i, (images, labels) in enumerate(loader):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      true += list(labels.cpu().numpy())\n",
        "      pred += list(predicted.cpu().numpy())\n",
        "  return pred, true"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQ7OKSmDNHAo"
      },
      "source": [
        "def main(model = 'vgg16', size = 32):\n",
        "  classes = get_classes()\n",
        "  datasets = prepare_data(size)\n",
        "  loaders = prepare_loader(datasets)\n",
        "  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  if model == 'vgg16':\n",
        "    print(\"vgg16\")\n",
        "    model = torchvision.models.vgg16()\n",
        "    model.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=3)\n",
        "  elif model == 'vgg19':\n",
        "    print(\"vgg19\")\n",
        "    model = torchvision.models.vgg19()\n",
        "    model.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=3)\n",
        "  elif model == 'resnet50':\n",
        "    print(\"resnet50\")\n",
        "    model = torchvision.models.resnet50()\n",
        "    model.fc = torch.nn.Linear(in_features=2048, out_features=3)\n",
        "\n",
        "  model.to(device)\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "  for epoch in range(10):\n",
        "    train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n",
        "    pred, true = test_epoch(epoch, model, loaders.test, device)\n",
        "    print(classification_report(true, pred, target_names=classes))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqrbWEc0bXtI",
        "outputId": "77106e42-dc48-4bcb-e9e7-f2586977b431"
      },
      "source": [
        "main('vgg16',32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vgg16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 step 31 ave_loss 1.0980\n",
            "Epoch 0 step 63 ave_loss 1.0927\n",
            "Epoch 0 step 95 ave_loss 1.0607\n",
            "Epoch 0 step 127 ave_loss 0.7948\n",
            "Epoch 0 step 159 ave_loss 0.6359\n",
            "Epoch 0 step 191 ave_loss 0.4811\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.57      0.44      0.50       409\n",
            "          3C       0.50      0.99      0.66       367\n",
            "          4C       1.00      0.67      0.81       831\n",
            "\n",
            "    accuracy                           0.69      1607\n",
            "   macro avg       0.69      0.70      0.65      1607\n",
            "weighted avg       0.78      0.69      0.69      1607\n",
            "\n",
            "Epoch 1 step 31 ave_loss 0.3340\n",
            "Epoch 1 step 63 ave_loss 0.2477\n",
            "Epoch 1 step 95 ave_loss 0.1329\n",
            "Epoch 1 step 127 ave_loss 0.2229\n",
            "Epoch 1 step 159 ave_loss 0.1590\n",
            "Epoch 1 step 191 ave_loss 0.2097\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.57      0.92      0.70       409\n",
            "          3C       0.62      0.94      0.75       367\n",
            "          4C       1.00      0.47      0.64       831\n",
            "\n",
            "    accuracy                           0.69      1607\n",
            "   macro avg       0.73      0.78      0.70      1607\n",
            "weighted avg       0.80      0.69      0.68      1607\n",
            "\n",
            "Epoch 2 step 31 ave_loss 0.1383\n",
            "Epoch 2 step 63 ave_loss 0.0487\n",
            "Epoch 2 step 95 ave_loss 0.0231\n",
            "Epoch 2 step 127 ave_loss 0.0160\n",
            "Epoch 2 step 159 ave_loss 0.0015\n",
            "Epoch 2 step 191 ave_loss 0.0141\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.89      0.87      0.88       409\n",
            "          3C       0.71      0.94      0.81       367\n",
            "          4C       1.00      0.87      0.93       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.87      0.89      0.87      1607\n",
            "weighted avg       0.91      0.89      0.89      1607\n",
            "\n",
            "Epoch 3 step 31 ave_loss 0.0003\n",
            "Epoch 3 step 63 ave_loss 0.0001\n",
            "Epoch 3 step 95 ave_loss 0.0001\n",
            "Epoch 3 step 127 ave_loss 0.0001\n",
            "Epoch 3 step 159 ave_loss 0.0001\n",
            "Epoch 3 step 191 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.86      0.87      0.86       409\n",
            "          3C       0.71      0.94      0.81       367\n",
            "          4C       1.00      0.85      0.92       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.86      0.89      0.86      1607\n",
            "weighted avg       0.90      0.87      0.88      1607\n",
            "\n",
            "Epoch 4 step 31 ave_loss 0.0001\n",
            "Epoch 4 step 63 ave_loss 0.0001\n",
            "Epoch 4 step 95 ave_loss 0.0001\n",
            "Epoch 4 step 127 ave_loss 0.0001\n",
            "Epoch 4 step 159 ave_loss 0.0001\n",
            "Epoch 4 step 191 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.84      0.87      0.85       409\n",
            "          3C       0.71      0.94      0.81       367\n",
            "          4C       1.00      0.84      0.91       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.85      0.88      0.86      1607\n",
            "weighted avg       0.89      0.87      0.87      1607\n",
            "\n",
            "Epoch 5 step 31 ave_loss 0.0001\n",
            "Epoch 5 step 63 ave_loss 0.0001\n",
            "Epoch 5 step 95 ave_loss 0.0001\n",
            "Epoch 5 step 127 ave_loss 0.0001\n",
            "Epoch 5 step 159 ave_loss 0.0001\n",
            "Epoch 5 step 191 ave_loss 0.0001\n"
          ]
        }
      ]
    }
  ]
}
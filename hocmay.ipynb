{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9799dergyIzK"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZB-sOqyyMat",
        "outputId": "51823882-c7cc-475c-ca30-8390a83b5fb7"
      },
      "source": [
        "!git clone https://github.com/haianh23102000/hoc_may.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'hoc_may' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RGRPTPTyzyH"
      },
      "source": [
        "def get_clases():\n",
        "  classes = ['2C', '3C', '4C']\n",
        "  return classes\n",
        "TrainTest = namedtuple('TrainTest', ['train', 'test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jSsPTzYy3zg"
      },
      "source": [
        "def prepare_data():\n",
        "  gaussianBlur = transforms.GaussianBlur(3)\n",
        "  histogramEqualize = transforms.RandomEqualize(p=0.5)\n",
        "  horizontal = transforms.RandomHorizontalFlip()\n",
        "  vertical = transforms.RandomVerticalFlip()\n",
        "  resize_224 = transforms.Resize((224,224))\n",
        "  crop_224 = transforms.RandomCrop(224, padding=4)\n",
        "  resize_32 = transforms.Resize((32,32))\n",
        "  crop_32 = transforms.RandomCrop(32, padding=4)\n",
        "  tensor = transforms.ToTensor()\n",
        "  transform_train_raw224 = transforms.Compose([resize_224, tensor])\n",
        "  transform_train_aug224 = transforms.Compose([resize_224, crop_224, horizontal, vertical, tensor])\n",
        "  transform_train_pre224 = transforms.Compose([resize_224, gaussianBlur, histogramEqualize, tensor])\n",
        "  transform_test_224 = transforms.Compose([resize_224, tensor])\n",
        "  transform_train_raw232 = transforms.Compose([resize_32, tensor])\n",
        "  transform_train_aug32 = transforms.Compose([resize_32, crop_32, horizontal, vertical, tensor])\n",
        "  transform_train_pre32 = transforms.Compose([resize_32, gaussianBlur, histogramEqualize, tensor])\n",
        "  transform_test_32 = transforms.Compose([resize_32, tensor])\n",
        "  trainset = torchvision.datasets.ImageFolder(root=traindir, transform=transform_train_aug224)\n",
        "  testset = torchvision.datasets.ImageFolder(root=testdir, transform=transform_test_224)\n",
        "  return TrainTest(train=trainset, test=testset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMDJj1Uqy6wW"
      },
      "source": [
        "def prepare_loader(datasets):\n",
        "  trainloader = DataLoader(dataset=datasets.train, batch_size=35, shuffle=True, num_workers=4)\n",
        "  testloader = DataLoader(dataset=datasets.test, batch_size=35, shuffle=False, num_workers=4)\n",
        "  return TrainTest(train=trainloader, test=testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjpIbsj1y63a"
      },
      "source": [
        "def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n",
        "  true = []\n",
        "  pred = []\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  reporting_steps = 18\n",
        "  for i, (images, labels) in enumerate(loader):\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    true += list(labels.cpu().numpy())\n",
        "    _, predicted = torch.max(outputs, dim=1)\n",
        "    pred += list(predicted.cpu().numpy())\n",
        "    loss = loss_func(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "    if i % reporting_steps == reporting_steps-1:\n",
        "      print(f\"Epoch {epoch} step {i} ave_loss {running_loss/reporting_steps:.4f}\")\n",
        "      running_loss = 0.0\n",
        "  return pred, true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w--3C6VczA9S"
      },
      "source": [
        "def test_epoch(epoch, model, loader, device):\n",
        "  true = []\n",
        "  pred = [] \n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for i, (images, labels) in enumerate(loader):\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      true += list(labels.cpu().numpy())\n",
        "      pred += list(predicted.cpu().numpy())\n",
        "  return pred, true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51bXZfNGzDpn",
        "outputId": "431afe22-84fd-45c8-9489-940b4f6d0d43"
      },
      "source": [
        "def main(PATH='./model.pth', model_in=''):\n",
        "  classes = get_clases()\n",
        "  datasets = prepare_data()\n",
        "  loaders = prepare_loader(datasets)\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  torch.cuda.empty_cache()\n",
        "  if model_in == 'vgg16':\n",
        "    print(\"vgg16\")\n",
        "    model = torchvision.models.vgg16()\n",
        "    model.classifier[6] = torch.nn.modules.linear.Linear(in_features=4096, out_features=3, bias=True)\n",
        "    model.to(device=device)\n",
        "  elif model_in == 'resnet50':\n",
        "    print(\"resnet50\")\n",
        "    model = torchvision.models.resnet50(pretrained=False, progress=False)\n",
        "    model.fc = torch.nn.modules.linear.Linear(in_features=2048, out_features=3, bias=True)  \n",
        "    model.to(device=device)\n",
        "  elif model_in == 'desnet':\n",
        "    print(\"desnet\")\n",
        "    model = torchvision.models.densenet121(pretrained=False, progress=False)\n",
        "    model.classifier = torch.nn.modules.linear.Linear(in_features=1024, out_features=3, bias=True)\n",
        "    model.to(device=device)\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "  for epoch in range(10):\n",
        "    train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n",
        "    pred, true = test_epoch(epoch, model, loaders.test, device)\n",
        "    print(classification_report(true, pred, target_names=classes))\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "  return model\n",
        "model = main(PATH=\"./vgg16.pth\", model_in='vgg16')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vgg16\n",
            "Epoch 0 step 17 ave_loss 1.0968\n",
            "Epoch 0 step 35 ave_loss 1.0992\n",
            "Epoch 0 step 53 ave_loss 1.0896\n",
            "Epoch 0 step 71 ave_loss 1.0997\n",
            "Epoch 0 step 89 ave_loss 1.0956\n",
            "Epoch 0 step 107 ave_loss 1.0925\n",
            "Epoch 0 step 125 ave_loss 1.0850\n",
            "Epoch 0 step 143 ave_loss 1.0937\n",
            "Epoch 0 step 161 ave_loss 1.0905\n",
            "Epoch 0 step 179 ave_loss 1.0787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.38      0.58      0.46       409\n",
            "          3C       0.00      0.00      0.00       367\n",
            "          4C       0.59      0.70      0.64       831\n",
            "\n",
            "    accuracy                           0.51      1607\n",
            "   macro avg       0.32      0.43      0.37      1607\n",
            "weighted avg       0.40      0.51      0.45      1607\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 step 17 ave_loss 1.0728\n",
            "Epoch 1 step 35 ave_loss 1.0871\n",
            "Epoch 1 step 53 ave_loss 1.0581\n",
            "Epoch 1 step 71 ave_loss 1.0116\n",
            "Epoch 1 step 89 ave_loss 1.0658\n",
            "Epoch 1 step 107 ave_loss 1.0147\n",
            "Epoch 1 step 125 ave_loss 0.9955\n",
            "Epoch 1 step 143 ave_loss 0.9509\n",
            "Epoch 1 step 161 ave_loss 0.9440\n",
            "Epoch 1 step 179 ave_loss 0.9366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.33      0.85      0.48       409\n",
            "          3C       0.25      0.39      0.31       367\n",
            "          4C       0.00      0.00      0.00       831\n",
            "\n",
            "    accuracy                           0.30      1607\n",
            "   macro avg       0.20      0.41      0.26      1607\n",
            "weighted avg       0.14      0.30      0.19      1607\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 step 17 ave_loss 1.0165\n",
            "Epoch 2 step 35 ave_loss 0.8571\n",
            "Epoch 2 step 53 ave_loss 0.9007\n",
            "Epoch 2 step 71 ave_loss 0.8082\n",
            "Epoch 2 step 89 ave_loss 0.9389\n",
            "Epoch 2 step 107 ave_loss 0.8082\n",
            "Epoch 2 step 125 ave_loss 0.7610\n",
            "Epoch 2 step 143 ave_loss 0.6933\n",
            "Epoch 2 step 161 ave_loss 0.7015\n",
            "Epoch 2 step 179 ave_loss 0.4587\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.44      0.58      0.50       409\n",
            "          3C       0.41      0.63      0.50       367\n",
            "          4C       0.89      0.54      0.67       831\n",
            "\n",
            "    accuracy                           0.57      1607\n",
            "   macro avg       0.58      0.58      0.56      1607\n",
            "weighted avg       0.67      0.57      0.59      1607\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 step 17 ave_loss 0.7955\n",
            "Epoch 3 step 35 ave_loss 0.5315\n",
            "Epoch 3 step 53 ave_loss 0.5374\n",
            "Epoch 3 step 71 ave_loss 0.5043\n",
            "Epoch 3 step 89 ave_loss 0.5198\n",
            "Epoch 3 step 107 ave_loss 0.4477\n",
            "Epoch 3 step 125 ave_loss 0.5052\n",
            "Epoch 3 step 143 ave_loss 0.4148\n",
            "Epoch 3 step 161 ave_loss 0.3738\n",
            "Epoch 3 step 179 ave_loss 0.3288\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.90      0.68      0.77       409\n",
            "          3C       0.54      0.82      0.65       367\n",
            "          4C       0.94      0.84      0.89       831\n",
            "\n",
            "    accuracy                           0.80      1607\n",
            "   macro avg       0.79      0.78      0.77      1607\n",
            "weighted avg       0.84      0.80      0.81      1607\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 step 17 ave_loss 0.4406\n",
            "Epoch 4 step 35 ave_loss 0.3102\n",
            "Epoch 4 step 53 ave_loss 0.2679\n",
            "Epoch 4 step 71 ave_loss 0.2389\n",
            "Epoch 4 step 89 ave_loss 0.2709\n",
            "Epoch 4 step 107 ave_loss 0.1393\n",
            "Epoch 4 step 125 ave_loss 0.2126\n",
            "Epoch 4 step 143 ave_loss 0.2171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2rmrRe0BALL"
      },
      "source": [
        "traindir = \"/content/hoc_may/Data/train\"\n",
        "testdir = \"/content/hoc_may/Data/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_kon5v_zMVA"
      },
      "source": [
        "def vid(model=None, testdir=None, device='cuda'):\n",
        "  if testdir == None:\n",
        "    testdir = torchvision.datasets.ImageFolder(root=testdir,transform=ransforms.Compose([resize_224, transforms.ToTensor()]))\n",
        "  video = namedtuple('video', ['id', \"label_true\", 'label_pred'])\n",
        "  id_list = []\n",
        "  for i, image in enumerate(testdir.imgs):\n",
        "    id = image[0].split(\"/\")[-1].split(\"_\")[0]\n",
        "    id_list.append(id)\n",
        "  vid_list = np.unique(id_list, return_counts=False)\n",
        "  true = []\n",
        "  pred = []\n",
        "  model.to(device)\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, labels in testdir:\n",
        "      images = images.unsqueeze(0).to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      true.append(labels)\n",
        "      pred += list(predicted.cpu().numpy())\n",
        "  outputs = []\n",
        "  true_vid = []\n",
        "  pred_vid = []\n",
        "  for id in vid_list:\n",
        "    true_vid = []\n",
        "    pred_vid = []\n",
        "    for index, img in enumerate(id_list):\n",
        "      if img == id:\n",
        "        pred_vid.append(pred[index])\n",
        "        true_vid.append(true[index])\n",
        "    value_true, count_true = np.unique(true_vid, return_counts=True)\n",
        "    label_true = value_true[np.where(count_true == np.max(count_true))]\n",
        "    value_pred, count_pred = np.unique(pred_vid, return_counts=True)\n",
        "    label_pred = value_pred[np.where(count_pred == np.max(count_pred))]\n",
        "    print(\"id:\", id, \", true:\", label_true, \", pred:\",label_pred)\n",
        "    true_video.append(label_true)\n",
        "    pred_video.append(label_pred)\n",
        "    outputs.append(video(id=id, label_true=label_true, label_pred=label_pred))\n",
        "  classes = get_clases()\n",
        "  print(classification_report(true_vid, pred_vid, target_names=classes))\n",
        "  return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbTa4ESVzOw2",
        "outputId": "6c135486-e66c-4358-e4e0-3af5f44d4627"
      },
      "source": [
        "vid(model=model, testdir=prepare_data().test, device='cuda')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id: 157 , true: [1] , pred: [1]\n",
            "id: 158 , true: [0] , pred: [0]\n",
            "id: 159 , true: [1] , pred: [1]\n",
            "id: 160 , true: [2] , pred: [2]\n",
            "id: 161 , true: [1] , pred: [1]\n",
            "id: 162 , true: [1] , pred: [1]\n",
            "id: 163 , true: [2] , pred: [2]\n",
            "id: 164 , true: [2] , pred: [2]\n",
            "id: 165 , true: [0] , pred: [0]\n",
            "id: 166 , true: [1] , pred: [1]\n",
            "id: 167 , true: [2] , pred: [2]\n",
            "id: 168 , true: [0] , pred: [0]\n",
            "id: 169 , true: [0] , pred: [0]\n",
            "id: 170 , true: [2] , pred: [1]\n",
            "id: 171 , true: [0] , pred: [0]\n",
            "id: 172 , true: [2] , pred: [2]\n",
            "id: 173 , true: [2] , pred: [0]\n",
            "id: 174 , true: [1] , pred: [0]\n",
            "id: 175 , true: [1] , pred: [1]\n",
            "id: 176 , true: [0] , pred: [0]\n",
            "id: 177 , true: [0] , pred: [0]\n",
            "id: 178 , true: [0] , pred: [0]\n",
            "id: 179 , true: [1] , pred: [0]\n",
            "id: 180 , true: [2] , pred: [2]\n",
            "id: 181 , true: [0] , pred: [1]\n",
            "id: 182 , true: [2] , pred: [2]\n",
            "id: 183 , true: [0] , pred: [0]\n",
            "id: 184 , true: [2] , pred: [2]\n",
            "id: 185 , true: [1] , pred: [0]\n",
            "id: 186 , true: [1] , pred: [1]\n",
            "id: 187 , true: [2] , pred: [2]\n",
            "id: 188 , true: [2] , pred: [2]\n",
            "id: 189 , true: [1] , pred: [1]\n",
            "id: 190 , true: [1] , pred: [1]\n",
            "id: 191 , true: [0] , pred: [0]\n",
            "id: 192 , true: [0] , pred: [0]\n",
            "id: 193 , true: [2] , pred: [0]\n",
            "id: 194 , true: [1] , pred: [1]\n",
            "id: 195 , true: [2] , pred: [0]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.65      0.92      0.76        12\n",
            "          3C       0.83      0.77      0.80        13\n",
            "          4C       1.00      0.71      0.83        14\n",
            "\n",
            "    accuracy                           0.79        39\n",
            "   macro avg       0.83      0.80      0.80        39\n",
            "weighted avg       0.84      0.79      0.80        39\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[video(id='157', label_true=array([1]), label_pred=array([1])),\n",
              " video(id='158', label_true=array([0]), label_pred=array([0])),\n",
              " video(id='159', label_true=array([1]), label_pred=array([1])),\n",
              " video(id='160', label_true=array([2]), label_pred=array([2])),\n",
              " video(id='161', label_true=array([1]), label_pred=array([1])),\n",
              " video(id='162', label_true=array([1]), label_pred=array([1])),\n",
              " video(id='163', label_true=array([2]), label_pred=array([2])),\n",
              " video(id='164', label_true=array([2]), label_pred=array([2])),\n",
              " video(id='165', label_true=array([0]), label_pred=array([0])),\n",
              " video(id='166', label_true=array([1]), label_pred=array([1])),\n",
              " video(id='167', label_true=array([2]), label_pred=array([2])),\n",
              " video(id='168', label_true=array([0]), label_pred=array([0])),\n",
              " video(id='169', label_true=array([0]), label_pred=array([0])),\n",
              " video(id='170', label_true=array([2]), label_pred=array([1])),\n",
              " video(id='171', label_true=array([0]), label_pred=array([0])),\n",
              " video(id='172', label_true=array([2]), label_pred=array([2])),\n",
              " video(id='173', label_true=array([2]), label_pred=array([0])),\n",
              " video(id='174', label_true=array([1]), label_pred=array([0])),\n",
              " video(id='175', label_true=array([1]), label_pred=array([1])),\n",
              " video(id='176', label_true=array([0]), label_pred=array([0])),\n",
              " video(id='177', label_true=array([0]), label_pred=array([0])),\n",
              " video(id='178', label_true=array([0]), label_pred=array([0])),\n",
              " video(id='179', label_true=array([1]), label_pred=array([0])),\n",
              " video(id='180', label_true=array([2]), label_pred=array([2])),\n",
              " video(id='181', label_true=array([0]), label_pred=array([1])),\n",
              " video(id='182', label_true=array([2]), label_pred=array([2])),\n",
              " video(id='183', label_true=array([0]), label_pred=array([0])),\n",
              " video(id='184', label_true=array([2]), label_pred=array([2])),\n",
              " video(id='185', label_true=array([1]), label_pred=array([0])),\n",
              " video(id='186', label_true=array([1]), label_pred=array([1])),\n",
              " video(id='187', label_true=array([2]), label_pred=array([2])),\n",
              " video(id='188', label_true=array([2]), label_pred=array([2])),\n",
              " video(id='189', label_true=array([1]), label_pred=array([1])),\n",
              " video(id='190', label_true=array([1]), label_pred=array([1])),\n",
              " video(id='191', label_true=array([0]), label_pred=array([0])),\n",
              " video(id='192', label_true=array([0]), label_pred=array([0])),\n",
              " video(id='193', label_true=array([2]), label_pred=array([0])),\n",
              " video(id='194', label_true=array([1]), label_pred=array([1])),\n",
              " video(id='195', label_true=array([2]), label_pred=array([0]))]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}